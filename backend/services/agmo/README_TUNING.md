# Sistema de Tuning de Hiperpar√¢metros - AGMO

Sistema completo para otimiza√ß√£o e valida√ß√£o de hiperpar√¢metros do algoritmo gen√©tico multiobjetivo (NSGA-II) para otimiza√ß√£o de portf√≥lios.

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Arquivos do Sistema](#arquivos-do-sistema)
- [Instala√ß√£o](#instala√ß√£o)
- [Como Usar](#como-usar)
- [M√©tricas Implementadas](#m√©tricas-implementadas)
- [Exemplos Pr√°ticos](#exemplos-pr√°ticos)
- [Interpreta√ß√£o dos Resultados](#interpreta√ß√£o-dos-resultados)
- [Recomenda√ß√µes para o TCC](#recomenda√ß√µes-para-o-tcc)

## üéØ Vis√£o Geral

Este sistema permite determinar cientificamente os melhores hiperpar√¢metros para o AGMO atrav√©s de:

1. **An√°lise de Converg√™ncia**: Determina quantas gera√ß√µes s√£o necess√°rias
2. **Grid Search**: Testa combina√ß√µes de popula√ß√£o √ó gera√ß√µes
3. **Valida√ß√£o Estat√≠stica**: M√∫ltiplas execu√ß√µes com an√°lise de vari√¢ncia
4. **Visualiza√ß√µes**: Gr√°ficos profissionais para o TCC

### Por que fazer tuning de hiperpar√¢metros?

- ‚úÖ Fundamenta√ß√£o cient√≠fica para escolha de par√¢metros
- ‚úÖ Evita desperd√≠cio computacional (gera√ß√µes excessivas)
- ‚úÖ Garante qualidade das solu√ß√µes (gera√ß√µes insuficientes)
- ‚úÖ Material robusto para metodologia do TCC
- ‚úÖ Permite compara√ß√µes objetivas

## üìÅ Arquivos do Sistema

```
backend/services/agmo/
‚îú‚îÄ‚îÄ quality_metrics.py                   # M√©tricas de qualidade (Hypervolume, Spread, etc)
‚îú‚îÄ‚îÄ hyperparameter_tuning_service.py     # Servi√ßo principal de tuning
‚îú‚îÄ‚îÄ exemplo_tuning.py                    # Exemplos de uso
‚îú‚îÄ‚îÄ agmo_service.py                      # (modificado) Suporte a callbacks
‚îî‚îÄ‚îÄ README_TUNING.md                     # Esta documenta√ß√£o
```

## üîß Instala√ß√£o

### 1. Instalar Depend√™ncias

```bash
cd backend
pip install -r requirements.txt
```

As novas depend√™ncias incluem:
- `pandas==2.1.3` - An√°lise de dados
- `matplotlib==3.8.2` - Gera√ß√£o de gr√°ficos
- `seaborn==0.13.0` - Visualiza√ß√µes estat√≠sticas

### 2. Verificar Instala√ß√£o

```bash
python -c "import matplotlib; import seaborn; print('OK')"
```

## üöÄ Como Usar

### Forma Mais Simples: Menu Interativo

```bash
cd backend/services/agmo
python exemplo_tuning.py
```

O menu oferece 5 op√ß√µes:
1. An√°lise de Converg√™ncia (recomendado para come√ßar)
2. Grid Search B√°sico
3. Grid Search Completo (para TCC)
4. An√°lise por Perfil de Risco
5. Teste R√°pido (valida√ß√£o)

### Uso Program√°tico

```python
from app import create_app
from services.agmo.hyperparameter_tuning_service import HyperparameterTuningService

app = create_app()
tuning_service = HyperparameterTuningService(app)

# An√°lise de converg√™ncia
resultados = tuning_service.convergence_analysis(
    ids_ativos=[1, 2, 3, 4, 5],
    nivel_risco='moderado',
    max_generations=200,
    population_size=100,
    n_runs=5
)

print(f"Converg√™ncia m√©dia: {resultados['convergence_mean']:.1f} gera√ß√µes")

# Grid search
summary = tuning_service.grid_search(
    ids_ativos=[1, 2, 3, 4, 5],
    nivel_risco='moderado',
    population_sizes=[50, 100, 200],
    generation_counts=[25, 50, 100],
    n_runs=3
)

# Melhor configura√ß√£o
best_config = tuning_service.get_best_configuration()
print(f"Melhor config: {best_config}")
```

## üìä M√©tricas Implementadas

### 1. Hypervolume (HV)
- **O que √©**: Volume do espa√ßo de objetivos dominado pela fronteira de Pareto
- **Interpreta√ß√£o**: Maior = melhor qualidade das solu√ß√µes
- **Uso**: M√©trica principal para comparar configura√ß√µes

### 2. Spread
- **O que √©**: Diversidade e extens√£o da fronteira de Pareto
- **Interpreta√ß√£o**: Menor = melhor distribui√ß√£o das solu√ß√µes
- **Uso**: Garante que temos solu√ß√µes variadas

### 3. Spacing
- **O que √©**: Uniformidade da distribui√ß√£o das solu√ß√µes
- **Interpreta√ß√£o**: Menor = distribui√ß√£o mais uniforme
- **Uso**: Complementa a an√°lise de diversidade

### 4. Pareto Size
- **O que √©**: N√∫mero de solu√ß√µes n√£o-dominadas
- **Interpreta√ß√£o**: Mais solu√ß√µes = mais op√ß√µes para o usu√°rio
- **Uso**: Deve ser balanceado (nem muito pequeno, nem excessivo)

## üí° Exemplos Pr√°ticos

### Exemplo 1: Determinar N√∫mero M√≠nimo de Gera√ß√µes

**Objetivo**: Evitar executar mais gera√ß√µes que o necess√°rio.

```python
resultados = tuning_service.convergence_analysis(
    ids_ativos=lista_ativos,
    nivel_risco='moderado',
    max_generations=200,  # Testa at√© 200
    population_size=100,
    n_runs=5  # 5 execu√ß√µes para m√©dia
)

# Resultado: "Converg√™ncia m√©dia em 87 gera√ß√µes"
# Recomenda√ß√£o: Use 100 gera√ß√µes (margem de seguran√ßa)
```

**Sa√≠da**: Gr√°fico mostrando evolu√ß√£o das m√©tricas ao longo das gera√ß√µes.

### Exemplo 2: Encontrar Melhor Popula√ß√£o

**Objetivo**: Balancear qualidade vs tempo computacional.

```python
summary = tuning_service.grid_search(
    ids_ativos=lista_ativos,
    nivel_risco='moderado',
    population_sizes=[50, 100, 150, 200, 300],
    generation_counts=[100],  # Fixa gera√ß√µes
    n_runs=5
)

# Resultado: Popula√ß√£o 150 tem melhor custo-benef√≠cio
```

**Sa√≠da**:
- Tabela comparativa
- Gr√°fico de trade-off qualidade vs tempo
- Heatmap de hypervolume

### Exemplo 3: Comparar Perfis de Risco

**Objetivo**: Verificar se perfis diferentes precisam de par√¢metros diferentes.

```python
for perfil in ['conservador', 'moderado', 'arrojado']:
    resultado = tuning_service.convergence_analysis(
        ids_ativos=lista_ativos,
        nivel_risco=perfil,
        max_generations=150,
        population_size=100,
        n_runs=5
    )
    print(f"{perfil}: {resultado['convergence_mean']:.1f} gera√ß√µes")

# Resultado t√≠pico:
# conservador: 92 gera√ß√µes
# moderado: 87 gera√ß√µes
# arrojado: 85 gera√ß√µes
# Conclus√£o: Diferen√ßa pequena, pode usar mesma config
```

## üìà Interpreta√ß√£o dos Resultados

### O que procurar nos gr√°ficos:

1. **Gr√°fico de Converg√™ncia (Hypervolume vs Gera√ß√µes)**
   - Procure onde a curva "estabiliza"
   - Ponto de estabiliza√ß√£o = converg√™ncia
   - Use esse valor + margem de 10-20%

2. **Heatmap de Configura√ß√µes**
   - Cores mais quentes = melhor hypervolume
   - Identifique "regi√£o √≥tima"
   - Evite cantos (muito pequeno ou muito grande)

3. **Trade-off Qualidade vs Tempo**
   - Procure o "joelho" da curva
   - Ponto onde tempo aumenta muito mas qualidade pouco
   - Esse √© o sweet spot

### Exemplo de Conclus√£o para TCC:

> "Atrav√©s de an√°lise sistem√°tica com 5 execu√ß√µes independentes,
> observou-se converg√™ncia m√©dia em 87¬±12 gera√ß√µes (m√©dia ¬± desvio padr√£o).
> O grid search testou 30 configura√ß√µes (5 popula√ß√µes √ó 6 gera√ß√µes √ó 3 runs),
> identificando popula√ß√£o=150 e gera√ß√µes=100 como configura√ß√£o √≥tima,
> apresentando hypervolume m√©dio de 0.8234¬±0.0156 com tempo de execu√ß√£o
> de 45.3¬±3.2 segundos. Esta configura√ß√£o representa o melhor trade-off
> entre qualidade da solu√ß√£o e custo computacional, sendo adotada para
> todas as otimiza√ß√µes subsequentes."

## üéì Recomenda√ß√µes para o TCC

### 1. Metodologia

Inclua na se√ß√£o de metodologia:
- Justificativa para tuning de hiperpar√¢metros
- Descri√ß√£o das m√©tricas usadas (HV, Spread, Spacing)
- Protocolo experimental (n_runs, configura√ß√µes testadas)
- Crit√©rios de converg√™ncia

### 2. Resultados

Apresente:
- Gr√°ficos de converg√™ncia para cada perfil
- Tabela comparativa de configura√ß√µes
- An√°lise estat√≠stica (m√©dia ¬± desvio padr√£o)
- Justificativa da escolha final

### 3. Discuss√£o

Discuta:
- Por que a configura√ß√£o escolhida √© √≥tima
- Sensibilidade dos resultados aos par√¢metros
- Limita√ß√µes (tempo computacional, dados dispon√≠veis)
- Compara√ß√£o com literatura (valores t√≠picos: pop=100-300, gen=50-200)

### 4. Material Visual Sugerido

**Figuras essenciais para o TCC:**
1. Gr√°fico de converg√™ncia (4 pain√©is: HV, Spread, Spacing, Pareto Size)
2. Histograma de gera√ß√µes de converg√™ncia
3. Heatmap de configura√ß√µes
4. Trade-off qualidade vs tempo
5. Compara√ß√£o entre perfis de risco

**Tabelas essenciais:**
1. Resumo de configura√ß√µes testadas
2. Estat√≠sticas descritivas (m√©dia, std, min, max)
3. Configura√ß√£o final escolhida com justificativa

## üî¨ Valores de Refer√™ncia

Com base na literatura de NSGA-II e otimiza√ß√£o de portf√≥lio:

### Regra de Bolso
- **Popula√ß√£o**: 10 √ó n_objectives √ó ‚àön_variables
  - Para 3 objetivos e 10 ativos: `10 √ó 3 √ó ‚àö10 ‚âà 95`
  - **Faixa razo√°vel: 50-300**

- **Gera√ß√µes**: Depende da converg√™ncia observada
  - **Faixa t√≠pica: 50-200**
  - Problemas simples: 50-100
  - Problemas complexos: 100-200

### Sinais de Problema

‚ùå **Popula√ß√£o muito pequena (< 50)**:
- Baixa diversidade
- Converg√™ncia prematura
- Fronteira de Pareto incompleta

‚ùå **Popula√ß√£o muito grande (> 500)**:
- Desperd√≠cio computacional
- Tempo excessivo
- Ganho marginal de qualidade

‚ùå **Gera√ß√µes insuficientes**:
- Hypervolume ainda crescendo
- Alta vari√¢ncia entre execu√ß√µes
- Solu√ß√µes sub√≥timas

‚ùå **Gera√ß√µes excessivas**:
- Hypervolume est√°vel h√° muitas gera√ß√µes
- Tempo desperdi√ßado
- Risco de overfitting

## üêõ Troubleshooting

### Problema: "Sem dados hist√≥ricos dispon√≠veis"
**Solu√ß√£o**: Verifique se h√° dados no banco para os ativos selecionados.

### Problema: Tempo muito longo
**Solu√ß√£o**:
1. Comece com teste r√°pido (Exemplo 5)
2. Use menos ativos inicialmente
3. Reduza n_runs para 3
4. Use time_limit no grid_search

### Problema: Resultados inconsistentes (alta vari√¢ncia)
**Solu√ß√£o**:
1. Aumente n_runs (m√≠nimo 5, ideal 10)
2. Verifique qualidade dos dados hist√≥ricos
3. Aumente popula√ß√£o (mais diversidade)

### Problema: Gr√°ficos n√£o aparecem
**Solu√ß√£o**:
```bash
# Linux
export MPLBACKEND=Agg

# Windows
set MPLBACKEND=Agg
```

## üìö Refer√™ncias

1. Deb, K., et al. (2002). "A fast and elitist multiobjective genetic algorithm: NSGA-II"
2. Blank, J., & Deb, K. (2020). "pymoo: Multi-Objective Optimization in Python"
3. Zitzler, E., et al. (2003). "Performance assessment of multiobjective optimizers"

## üìû Suporte

Para d√∫vidas ou problemas:
1. Verifique esta documenta√ß√£o
2. Execute o Exemplo 5 (Teste R√°pido) para validar instala√ß√£o
3. Consulte os logs em `tuning_results/`

---

**√öltima atualiza√ß√£o**: Outubro 2025
**Autor**: Sistema de Otimiza√ß√£o de Portf√≥lio - TCC
