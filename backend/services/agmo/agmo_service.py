from dateutil.relativedelta import relativedelta
from pymoo.config import Config

from routes.carteira_routes import carteira_bp
from services.agmo.custom_crossover import SimplexCrossover, SimplexMutation, SimplexSampling

Config.warnings['not_compiled'] = False

import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from pymoo.core.problem import ElementwiseProblem
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.optimize import minimize
from otimizacao_utils import _printar_matriz

from app import create_app
from models import db, Ativo, HistoricoPrecos
from models.ativo import TipoAtivo

import matplotlib.pyplot as plt

# --------------------------------------------------------------------------
# 1. CLASSE DO PROBLEMA PARA O PYMOO
#    Agora ela recebe os par√¢metros do usu√°rio para guiar a otimiza√ß√£o.
# --------------------------------------------------------------------------
class PersonalizedPortfolioProblem(ElementwiseProblem):
    """
    Problema de otimiza√ß√£o de portf√≥lio com 3 objetivos, personalizado
    pelo perfil de risco do usu√°rio.
    """

    def __init__(self, retornos_medios, matriz_covariancia, historico_retornos, tickers, nivel_risco, alpha=0.05, peso_min=0.01, peso_max=0.30):
        n_ativos = len(retornos_medios)
        # ‚úÖ Limites por ativo
        xl = np.full(n_ativos, peso_min)
        xu = np.full(n_ativos, peso_max)
        # n_ieq_constr=numero de restri√ß√µes / n_eq_constr=numero de restri√ß√µes de soma
        super().__init__(n_var=n_ativos,
                         n_obj=3,
                         n_ieq_constr=1,
                         n_eq_constr=0,
                         xl=0.01, xu=1)
        self.mu = retornos_medios
        self.cov = matriz_covariancia
        self.hist = historico_retornos
        self.tickers = tickers
        self.nivel_risco = nivel_risco
        self.alpha = alpha
        self.peso_min = peso_min
        self.peso_max = peso_max

    def _calcular_cvar(self, pesos):
        """Calcula o Conditional Value-at-Risk para uma dada carteira."""
        retornos_portfolio = self.hist @ pesos
        perdas = -retornos_portfolio
        perdas_validas = perdas[np.isfinite(perdas)]

        if len(perdas_validas) < 20:  # ‚úÖ M√≠nimo de dados
            return np.std(perdas_validas)  # Fallback para desvio padr√£o

        perdas_ordenadas = np.sort(perdas_validas)
        k = max(1, int(self.alpha * len(perdas_ordenadas)))  # ‚úÖ M√≠nimo de 1

        # CVaR = m√©dia das perdas acima do VaR
        cvar = perdas_ordenadas[-k:].mean()
        return cvar

    def _evaluate(self, x, out, *args, **kwargs):
        """Avalia uma √∫nica carteira"""

        # # ========== DEBUG ==========
        # print(f"\n{'=' * 70}")
        # print(f"üîç DEBUG _evaluate")
        # print(f"{'=' * 70}")
        #
        # print(f"\nüìä Vetor x (RAW - antes da normaliza√ß√£o):")
        # print(f"   Shape: {x.shape}")
        # print(f"   Valores: {x}")
        # print(f"   Soma: {x.sum():.6f}")
        # print(f"   Min: {x.min():.6f}")
        # print(f"   Max: {x.max():.6f}")
        #
        # print(f"\nüíº Mapeamento x ‚Üí Ativos:")
        # for i, (ticker, peso_raw) in enumerate(zip(self.tickers, x)):
        #     print(f"   x[{i}] = {peso_raw:.6f} ‚Üí {ticker}")

        """Avalia uma √∫nica carteira (x = vetor de pesos)."""
        pesos = x
        # ‚úÖ NORMALIZA SEMPRE
        # pesos = np.maximum(x, 0)
        # pesos = pesos / pesos.sum()  # GARANTE soma = 1

        # --- Objetivos ---
        # Obj 1: Retorno esperado (negativo porque o pymoo minimiza)
        retorno = -np.dot(pesos, self.mu)

        # Obj 2: Risco (vari√¢ncia)
        variancia = np.dot(pesos, self.cov @ pesos)

        # Obj 3: Risco de cauda (CVaR)
        cvar = self._calcular_cvar(pesos)

        # --- AJUSTE DOS OBJETIVOS PELO PERFIL DE RISCO ---
        # Penaliza mais o risco para perfis conservadores e menos para arrojados.
        # Isso "empurra" o algoritmo para as regi√µes da Fronteira de Pareto desejadas.
        if self.nivel_risco == 'conservador':
            variancia *= 1.5
            cvar *= 2.0
        elif self.nivel_risco == 'arrojado':
            variancia *= 0.8
            cvar *= 0.8
        # Para 'moderado', n√£o fazemos nada (peso 1.0)

        # ‚úÖ Diversifica√ß√£o: nenhum ativo deve ter mais que peso_max
        restricao_concentracao = np.max(pesos) - self.peso_max

        # Restri√ß√£o de IGUALDADE (soma = 1)
        restricao_eq = np.sum(pesos) - 1.0  # h(x) = 0

        out["F"] = [retorno, variancia, cvar]
        out["G"] =  [restricao_concentracao] # ‚úÖ Restri√ß√£o de concentra√ß√£o
       # out["H"] = [restricao_eq]  # ‚úÖ Restri√ß√£o de igualdade

# --------------------------------------------------------------------------
# 2. SERVI√áO PRINCIPAL DE OTIMIZA√á√ÉO
#    Ele agora orquestra o processo usando os par√¢metros do usu√°rio.
# --------------------------------------------------------------------------
class Nsga2OtimizacaoService:
    def __init__(self, app, ids_ativos_restringidos, nivel_risco, prazo_anos, data_referencia=None, data_inicio=None):
        """
        Servi√ßo de otimiza√ß√£o de carteira usando NSGA-II.

        Args:
            app: Inst√¢ncia da aplica√ß√£o Flask
            ids_ativos_restringidos: Lista de IDs de ativos a serem exclu√≠dos da otimiza√ß√£o
            nivel_risco: Perfil de risco ('conservador', 'moderado', 'arrojado')
            prazo_anos: Prazo do investimento em anos
            data_referencia: Data de refer√™ncia para backtest (opcional). Se fornecida,
                           usa apenas dados hist√≥ricos at√© essa data. Formato: datetime.date
        """
        self.app = app
        self.ids_ativos_restringidos = ids_ativos_restringidos
        self.nivel_risco = nivel_risco
        self.prazo_anos = prazo_anos
        self.data_referencia = data_referencia
        # Data inicial da janela de an√°lise
        self.data_inicio = data_inicio
        self.ativos_para_otimizar = []
        self.retornos_medios = None
        self.matriz_covariancia = None
        self.historico_retornos = None
        self.tickers = None

    def _preparar_dados(self):
        """Busca dados e aplica o ajuste de risco pelo prazo."""
        with self.app.app_context():
            query_ativos = db.session.query(Ativo).filter(
                ~Ativo.id.in_(self.ids_ativos_restringidos),
                Ativo.tipo == TipoAtivo.ACAO
            )
            self.ativos_para_otimizar = query_ativos.all()
            if len(self.ativos_para_otimizar) < 3:  # M√≠nimo para 3 objetivos
                raise ValueError("S√£o necess√°rios pelo menos 3 ativos do tipo 'A√ß√£o' para a otimiza√ß√£o.")

            ids_para_otimizar = [a.id for a in self.ativos_para_otimizar]
            query_historico = db.session.query(
                HistoricoPrecos.data,
                HistoricoPrecos.variacao_mensal,
                Ativo.ticker
            ).join(Ativo, HistoricoPrecos.id_ativo == Ativo.id) \
                .filter(HistoricoPrecos.id_ativo.in_(ids_para_otimizar))

            # ‚úÖ BACKTEST: Se data_referencia foi fornecida, filtra apenas dados at√© essa data
            if self.data_referencia is not None:
                if self.data_inicio is not None:
                    query_historico = query_historico.filter(HistoricoPrecos.data >= self.data_inicio)

                query_historico = query_historico.filter(HistoricoPrecos.data <= self.data_referencia)
                print(f"  üìÖ MODO BACKTEST: Usando dados at√© {self.data_referencia}")

            query_historico = query_historico.order_by(HistoricoPrecos.data)

            # ‚úÖ CORRE√á√ÉO: Usar connection em vez de bind
            df_historico = pd.read_sql(
                query_historico.statement,
                con=db.session.connection()
            )
            if df_historico.empty:
                raise ValueError("Sem hist√≥rico para os ativos selecionados.")

            # Limita os hist√≥ricos para o ativo que tem o hist√≥rico mais curto
            df_retornos = df_historico.pivot(index='data', columns='ticker', values='variacao_mensal').dropna()

            self.tickers = df_retornos.columns.tolist()

            # ‚úÖ Valida√ß√£o de dados suficientes
            if len(df_retornos) < 12:  # M√≠nimo de 12 meses para an√°lise
                raise ValueError(f"Dados hist√≥ricos insuficientes para an√°lise. "
                               f"Encontrados {len(df_retornos)} meses, m√≠nimo necess√°rio: 12 meses.")

            if self.data_referencia is not None:
                print(f"\n{'=' * 70}")
                print(f"üìÖ MODO BACKTEST ATIVADO")
                print(f"{'=' * 70}")
                print(f"  Data de refer√™ncia: {self.data_referencia}")
                print(f"  ‚ö†Ô∏è  Usando APENAS dados hist√≥ricos at√© essa data")

            print(f"\n  ‚úÖ Per√≠odo hist√≥rico: {len(df_retornos)} meses")
            print(f"  üìÖ De {df_retornos.index.min()} at√© {df_retornos.index.max()}")

            # Calcular estat√≠sticas
            self.retornos_medios = df_retornos.mean()
            self.matriz_covariancia = df_retornos.cov()
            matriz_corr = df_retornos.corr()

            # ‚úÖ PRINTAR MATRIZ DE CORRELA√á√ÉO
            print(f"\n{'=' * 70}")
            print(f"üìä MATRIZ DE CORRELA√á√ÉO")
            print(f"{'=' * 70}")
            _printar_matriz(matriz_corr, formato=".3f")

            # An√°lise da correla√ß√£o
            self._analisar_correlacao(matriz_corr)

            # ‚úÖ PRINTAR MATRIZ DE COVARI√ÇNCIA
            print(f"\n{'=' * 70}")
            print(f"üìä MATRIZ DE COVARI√ÇNCIA (Mensal)")
            print(f"{'=' * 70}")
            _printar_matriz(self.matriz_covariancia, formato=".6f")

            self.historico_retornos = df_retornos

            # Estat√≠sticas gerais
            print(f"\n{'=' * 70}")
            print(f"üìä ESTAT√çSTICAS GERAIS")
            print(f"{'=' * 70}")
            print(f"  Retorno m√©dio mensal: {self.retornos_medios.mean() * 100:.2f}%")
            print(f"  Volatilidade m√©dia: {np.sqrt(np.diag(self.matriz_covariancia)).mean() * 100:.2f}%")

            # Estat√≠sticas por ativo
            print(f"\n  üìà Por Ativo:")
            for ticker in df_retornos.columns:
                ret = self.retornos_medios[ticker] * 100
                vol = np.sqrt(self.matriz_covariancia.loc[ticker, ticker]) * 100
                sharpe = ret / vol if vol > 0 else 0
                print(f"     {ticker:8s} | Ret: {ret:6.2f}% | Vol: {vol:6.2f}% | Sharpe: {sharpe:5.2f}")

            print(f"\n  ‚úÖ Dados preparados com sucesso!")

    def _analisar_correlacao(self, matriz_corr):
        """
        Analisa e printa insights da matriz de correla√ß√£o
        """
        print(f"\n  üîç An√°lise de Correla√ß√£o:")

        # Extrair apenas metade superior (sem diagonal)
        mask = np.triu(np.ones_like(matriz_corr, dtype=bool), k=1)
        correlacoes = matriz_corr.where(mask).stack()

        # Estat√≠sticas
        print(f"     Correla√ß√£o M√©dia: {correlacoes.mean():.3f}")
        print(f"     Correla√ß√£o M√°xima: {correlacoes.max():.3f}")
        print(f"     Correla√ß√£o M√≠nima: {correlacoes.min():.3f}")

        # Pares com correla√ß√£o muito alta (> 0.8)
        altas = correlacoes[correlacoes > 0.8].sort_values(ascending=False)
        if len(altas) > 0:
            print(f"\n  ‚ö†Ô∏è  Pares com Correla√ß√£o ALTA (> 0.8):")
            for par, corr in altas.head(5).items():
                print(f"     {par[0]:8s} ‚Üî {par[1]:8s}: {corr:.3f}")

        # Pares com correla√ß√£o negativa (< -0.3)
        negativas = correlacoes[correlacoes < -0.3].sort_values()
        if len(negativas) > 0:
            print(f"\n  ‚úÖ Pares com Correla√ß√£o NEGATIVA (< -0.3) [Boa diversifica√ß√£o!]:")
            for par, corr in negativas.head(5).items():
                print(f"     {par[0]:8s} ‚Üî {par[1]:8s}: {corr:.3f}")

        # Aviso se tudo muito correlacionado
        if correlacoes.mean() > 0.7:
            print(f"\n  ‚ö†Ô∏è  ATEN√á√ÉO: Ativos muito correlacionados (m√©dia {correlacoes.mean():.2f})")
            print(f"     Considere adicionar ativos de outros setores para diversifica√ß√£o.")

    def _escolher_melhor_carteira(self, objetivos, solucoes):
        """Seleciona a melhor carteira da Fronteira de Pareto com base no perfil de risco."""
        print(f"Selecionando a melhor solu√ß√£o para o perfil '{self.nivel_risco}'...")

        # Normaliza os objetivos para que fiquem na mesma escala (0 a 1)
        # Obj 0 (Retorno) √© negativo, ent√£o invertemos o sinal para normalizar
        # Inverte retorno (era negativo)
        objetivos = objetivos.copy()
        objetivos[:, 0] = -objetivos[:, 0]

        # Normaliza√ß√£o mais robusta
        objetivos_norm = np.zeros_like(objetivos)
        for i in range(objetivos.shape[1]):
            col = objetivos[:, i]
            min_val, max_val = col.min(), col.max()

            if max_val - min_val > 1e-10:  # Evita divis√£o por zero
                objetivos_norm[:, i] = (col - min_val) / (max_val - min_val)
            else:
                objetivos_norm[:, i] = 0.5  # Valor neutro

        # Pesos para cada objetivo [Retorno, Vari√¢ncia, CVaR]
        pesos_perfil = {
            'conservador': np.array([0.2, 0.5, 0.3]),  # Prioriza minimizar riscos
            'moderado': np.array([0.4, 0.3, 0.3]),  # Equilibrado
            'arrojado': np.array([0.6, 0.2, 0.2])  # Prioriza maximizar retorno
        }
        pesos = pesos_perfil[self.nivel_risco]

        # Calcula um "score" para cada carteira.
        # Queremos maximizar o retorno (objetivo 0) e minimizar os outros (1 e 2).
        scores = ((objetivos_norm[:, 0] * pesos[0]) - (objetivos_norm[:, 1] * pesos[1]))
              #    - (objetivos_norm[:, 2] * pesos[2]))

        # O √≠ndice da carteira com o maior score √© a nossa escolha.
        idx_melhor = np.argmax(scores)
        return solucoes[idx_melhor]

    def otimizar(self):
        """
        Orquestra o processo completo de otimiza√ß√£o personalizada.

        Returns:
            dict: Dicion√°rio contendo:
                - composicao: Lista de dicion√°rios com id_ativo, ticker e peso
                - data_referencia: Data de refer√™ncia usada (None se n√£o for backtest)
                - periodo_inicio: Data inicial dos dados hist√≥ricos usados
                - periodo_fim: Data final dos dados hist√≥ricos usados
                - num_meses: N√∫mero de meses de dados hist√≥ricos utilizados
        """
        self._preparar_dados()

        problema = PersonalizedPortfolioProblem(
            retornos_medios=self.retornos_medios.values,
            matriz_covariancia=self.matriz_covariancia.values,
            historico_retornos=self.historico_retornos.values,
            tickers = self.tickers,
            nivel_risco=self.nivel_risco
        )

        sampling = SimplexSampling()
        crossover = SimplexCrossover(eta=15)
        mutation = SimplexMutation(eta=20)

        algoritmo = NSGA2(pop_size=100, crossover=crossover, mutation=mutation, sampling=sampling)
        resultado = minimize(problema, algoritmo, ('n_gen', 50), verbose=True)
        print("üèÅ Otimiza√ß√£o NSGA-II conclu√≠da.")

        if resultado.X is None:
            raise ValueError("O algoritmo n√£o conseguiu encontrar nenhuma solu√ß√£o.")

        # Seleciona a melhor carteira da fronteira de Pareto
        pesos_otimos = self._escolher_melhor_carteira(resultado.F, resultado.X)

        F = resultado.F
        plt.scatter(F[:, 1], -F[:, 0], c=F[:, 2], cmap='viridis')
        plt.xlabel("Risco (vari√¢ncia)")
        plt.ylabel("Retorno esperado")
        plt.colorbar(label="CVaR")
        plt.title("Fronteira de Pareto - NSGA-II")
        plt.show()

        composicao_final = []
        for i, ativo in enumerate(self.ativos_para_otimizar):
            peso = pesos_otimos[i]
            if peso > 0.001:  # Ignora pesos insignificantes
                composicao_final.append({
                    'id_ativo': ativo.id,
                    'ticker': ativo.ticker,
                    'nome': ativo.nome,
                    'peso': float(peso)
                })

        # Normalizar pesos para soma = 1
        soma_pesos = sum(item['peso'] for item in composicao_final)
        for item in composicao_final:
            item['peso'] = item['peso'] / soma_pesos

        print(f"  ‚úÖ Carteira otimizada com {len(composicao_final)} ativos")

        # ‚úÖ RETORNA informa√ß√µes adicionais sobre o per√≠odo usado (√∫til para backtest)
        resultado = {
            'composicao': composicao_final,
            'data_referencia': self.data_referencia,
            'periodo_inicio': self.historico_retornos.index.min(),
            'periodo_fim': self.historico_retornos.index.max(),
            'num_meses': len(self.historico_retornos),
            'modo_backtest': self.data_referencia is not None
        }

        return resultado


def _calcular_retorno_carteira(app, carteira: List[Dict],
                               data_inicio,
                               data_fim) -> Tuple[float, List[float]]:
    """
    Calcula o retorno de uma carteira em um per√≠odo espec√≠fico

    Args:
        carteira: Lista com composi√ß√£o da carteira
        data_inicio: Data inicial do per√≠odo
        data_fim: Data final do per√≠odo

    Returns:
        Tupla com (retorno_total, lista_de_retornos_mensais)
    """
    with app.app_context():
        # Buscar retornos dos ativos no per√≠odo
        ids_ativos = [item['id_ativo'] for item in carteira]

        query = db.session.query(
            HistoricoPrecos.data,
            HistoricoPrecos.variacao_mensal,
            Ativo.ticker
        ).join(Ativo, HistoricoPrecos.id_ativo == Ativo.id) \
            .filter(
            HistoricoPrecos.id_ativo.in_(ids_ativos),
            HistoricoPrecos.data > data_inicio,
            HistoricoPrecos.data <= data_fim
        ) \
            .order_by(HistoricoPrecos.data)

        df = pd.read_sql(query.statement, con=db.session.connection())

        if df.empty:
            return 0.0, []

        # Pivot para ter retornos por ativo
        df_retornos = df.pivot(
            index='data',
            columns='ticker',
            values='variacao_mensal'
        )

        # Calcular retorno ponderado da carteira
        pesos_dict = {item['ticker']: item['peso'] for item in carteira}

        retornos_mensais = []
        for data_idx in df_retornos.index:
            retorno_mes = 0
            for ticker in df_retornos.columns:
                if ticker in pesos_dict:
                    ret_ativo = df_retornos.loc[data_idx, ticker]
                    if pd.notna(ret_ativo):
                        retorno_mes += pesos_dict[ticker] * ret_ativo

            retornos_mensais.append(retorno_mes)

        # Calcular retorno acumulado
        retorno_total = (1 + pd.Series(retornos_mensais)).prod() - 1

        return float(retorno_total), retornos_mensais


def otimizar_carteira_atual(app):
    print("\n" + "=" * 80)
    print("EXEMPLO 1: Otimiza√ß√£o normal (usando todos os dados dispon√≠veis)")
    print("=" * 80)
    service = Nsga2OtimizacaoService(app, [1], "conservador", 2)
    resultado = service.otimizar()
    print(f"\n‚úÖ Resultado:")
    print(f"   Composi√ß√£o: {resultado['composicao']}")
    print(f"   Per√≠odo: {resultado['periodo_inicio']} at√© {resultado['periodo_fim']}")
    print(f"   Meses: {resultado['num_meses']}")

def backtest(app):
    from datetime import date
    print("\n" + "=" * 80)
    print("EXEMPLO 2: Otimiza√ß√£o com BACKTEST (dados at√© 2023-12-31)")
    print("=" * 80)
    data_backtest = date(2015, 12, 31)
    service_backtest = Nsga2OtimizacaoService(app, [1, 7], "conservador", 2, data_referencia=data_backtest)
    carteira_backtest = service_backtest.otimizar()
    print(f"\n‚úÖ Resultado do Backtest:")
    print(f"   Composi√ß√£o: {carteira_backtest['composicao']}")
    print(f"   Data de refer√™ncia: {carteira_backtest['data_referencia']}")
    print(f"   Per√≠odo: {carteira_backtest['periodo_inicio']} at√© {carteira_backtest['periodo_fim']}")
    print(f"   Meses: {carteira_backtest['num_meses']}")
    print(f"   Modo Backtest: {carteira_backtest['modo_backtest']}")

    dataFim = date(2025, 10, 20)
    retorno_periodo, retornos_mensais = _calcular_retorno_carteira(
        app,
        carteira_backtest['composicao'],
        data_backtest,
        dataFim
    )

    # Calcular m√©tricas
    # retorno_acumulado_total = (1 + retorno_acumulado_total) * (1 + retorno_periodo) - 1

    if retornos_mensais:
        volatilidade = np.std(retornos_mensais) * np.sqrt(12)  # Anualizada
        retorno_medio = np.mean(retornos_mensais) * 12  # Anualizado
        sharpe = retorno_medio / volatilidade if volatilidade > 0 else 0
    else:
        volatilidade = 0
        sharpe = 0

    print(f"     Retorno Acumulado: {retorno_periodo * 100:+.2f}%")


def main():
    """Fun√ß√£o principal que interpreta os comandos."""
    app = create_app()

    # Exemplo 1: Otimiza√ß√£o normal (sem backtest)
 #   otimizar_carteira_atual(app)

    # Exemplo 2: Otimiza√ß√£o com backtest (usando dados at√© uma data espec√≠fica)
    backtest(app)


if __name__ == "__main__":
    main()

