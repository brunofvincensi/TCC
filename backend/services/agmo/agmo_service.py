from pymoo.config import Config
from services.agmo.custom_crossover import SimplexCrossover, SimplexMutation, SimplexSampling

Config.warnings['not_compiled'] = False

import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
from pymoo.core.problem import ElementwiseProblem
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.optimize import minimize
from pymoo.core.callback import Callback
from otimizacao_utils import _printar_matriz

from app import create_app
from models import db, Ativo, HistoricoPrecos
from models.ativo import TipoAtivo

import matplotlib.pyplot as plt

# --------------------------------------------------------------------------
# 0. CALLBACK PARA RASTREAMENTO DE CONVERG√äNCIA
# --------------------------------------------------------------------------
class ConvergenceCallback(Callback):
    """
    Callback do pymoo para rastrear m√©tricas de converg√™ncia durante a otimiza√ß√£o.
    """

    def __init__(self, convergence_tracker=None):
        """
        Args:
            convergence_tracker: Inst√¢ncia de ConvergenceTracker para registrar m√©tricas
        """
        super().__init__()
        self.convergence_tracker = convergence_tracker

    def notify(self, algorithm):
        """
        Chamado a cada gera√ß√£o pelo pymoo.

        Args:
            algorithm: Inst√¢ncia do algoritmo com popula√ß√£o atual
        """
        if self.convergence_tracker is None:
            return

        # Extrai fronteira de Pareto atual
        if hasattr(algorithm, 'opt') and algorithm.opt is not None:
            pareto_front = algorithm.opt.get("F")
        else:
            # Se n√£o h√° Pareto, usa toda a popula√ß√£o
            pareto_front = algorithm.pop.get("F")

        # Fitness de toda a popula√ß√£o
        population_fitness = algorithm.pop.get("F")

        # Atualiza o tracker
        self.convergence_tracker.update(
            generation=algorithm.n_gen,
            pareto_front=pareto_front,
            population_fitness=population_fitness
        )

# --------------------------------------------------------------------------
# 1. CLASSE DO PROBLEMA PARA O PYMOO
#    Agora ela recebe os par√¢metros do usu√°rio para guiar a otimiza√ß√£o.
# --------------------------------------------------------------------------
class PersonalizedPortfolioProblem(ElementwiseProblem):
    """
    Problema de otimiza√ß√£o de portf√≥lio com 3 objetivos, personalizado
    pelo perfil de risco do usu√°rio.
    """

    def __init__(self, retornos_medios, matriz_covariancia, historico_retornos, tickers, nivel_risco, alpha=0.05, peso_min=0.01, peso_max=0.30):
        n_ativos = len(retornos_medios)
        # ‚úÖ Limites por ativo
        xl = np.full(n_ativos, peso_min)
        xu = np.full(n_ativos, peso_max)
        # n_ieq_constr=numero de restri√ß√µes / n_eq_constr=numero de restri√ß√µes de soma
        super().__init__(n_var=n_ativos,
                         n_obj=3,
                         n_ieq_constr=1,
                         n_eq_constr=0,
                         xl=0.01, xu=1)
        self.mu = retornos_medios
        self.cov = matriz_covariancia
        self.hist = historico_retornos
        self.tickers = tickers
        self.nivel_risco = nivel_risco
        self.alpha = alpha
        self.peso_min = peso_min
        self.peso_max = peso_max

    def _calcular_cvar(self, pesos):
        """Calcula o Conditional Value-at-Risk para uma dada carteira."""
        retornos_portfolio = self.hist @ pesos
        perdas = -retornos_portfolio
        perdas_validas = perdas[np.isfinite(perdas)]

        if len(perdas_validas) < 20:  # ‚úÖ M√≠nimo de dados
            return np.std(perdas_validas)  # Fallback para desvio padr√£o

        perdas_ordenadas = np.sort(perdas_validas)
        k = max(1, int(self.alpha * len(perdas_ordenadas)))  # ‚úÖ M√≠nimo de 1

        # CVaR = m√©dia das perdas acima do VaR
        cvar = perdas_ordenadas[-k:].mean()
        return cvar

    def _evaluate(self, x, out, *args, **kwargs):
        """Avalia uma √∫nica carteira"""

        # # ========== DEBUG ==========
        # print(f"\n{'=' * 70}")
        # print(f"üîç DEBUG _evaluate")
        # print(f"{'=' * 70}")
        #
        # print(f"\nüìä Vetor x (RAW - antes da normaliza√ß√£o):")
        # print(f"   Shape: {x.shape}")
        # print(f"   Valores: {x}")
        # print(f"   Soma: {x.sum():.6f}")
        # print(f"   Min: {x.min():.6f}")
        # print(f"   Max: {x.max():.6f}")
        #
        # print(f"\nüíº Mapeamento x ‚Üí Ativos:")
        # for i, (ticker, peso_raw) in enumerate(zip(self.tickers, x)):
        #     print(f"   x[{i}] = {peso_raw:.6f} ‚Üí {ticker}")

        """Avalia uma √∫nica carteira (x = vetor de pesos)."""
        pesos = x

        # --- Objetivos ---
        # Obj 1: Retorno esperado (negativo porque o pymoo minimiza)
        retorno = -np.dot(pesos, self.mu)

        # Obj 2: Risco (vari√¢ncia)
        variancia = np.dot(pesos, self.cov @ pesos)

        # Obj 3: Risco de cauda (CVaR)
        cvar = self._calcular_cvar(pesos)

        # --- AJUSTE DOS OBJETIVOS PELO PERFIL DE RISCO ---
        # Penaliza mais o risco para perfis conservadores e menos para arrojados.
        # Isso "empurra" o algoritmo para as regi√µes da Fronteira de Pareto desejadas.
        if self.nivel_risco == 'conservador':
            variancia *= 1.5
            cvar *= 2.0
        elif self.nivel_risco == 'arrojado':
            variancia *= 0.8
            cvar *= 0.8
        # Para 'moderado', n√£o fazemos nada (peso 1.0)

        # ‚úÖ Diversifica√ß√£o: nenhum ativo deve ter mais que peso_max
        restricao_concentracao = np.max(pesos) - self.peso_max

        # Restri√ß√£o de IGUALDADE (soma = 1)
        restricao_eq = np.sum(pesos) - 1.0  # h(x) = 0

        out["F"] = [retorno, variancia, cvar]
        out["G"] =  [restricao_concentracao] # ‚úÖ Restri√ß√£o de concentra√ß√£o
       # out["H"] = [restricao_eq]  # ‚úÖ Restri√ß√£o de igualdade

# --------------------------------------------------------------------------
# 2. SERVI√áO PRINCIPAL DE OTIMIZA√á√ÉO
#    Ele agora orquestra o processo usando os par√¢metros do usu√°rio.
# --------------------------------------------------------------------------
class Nsga2OtimizacaoService:
    def __init__(self, app, ids_ativos_restringidos, nivel_risco, prazo_anos, data_referencia=None, data_inicio=None):
        """
        Servi√ßo de otimiza√ß√£o de carteira usando NSGA-II.

        Args:
            app: Inst√¢ncia da aplica√ß√£o Flask
            ids_ativos_restringidos: Lista de IDs de ativos a serem exclu√≠dos da otimiza√ß√£o
            nivel_risco: Perfil de risco ('conservador', 'moderado', 'arrojado')
            prazo_anos: Prazo do investimento em anos
            data_referencia: Data de refer√™ncia para backtest (opcional). Se fornecida,
                           usa apenas dados hist√≥ricos at√© essa data. Formato: datetime.date
        """
        self.app = app
        self.ids_ativos_restringidos = ids_ativos_restringidos
        self.nivel_risco = nivel_risco
        self.prazo_anos = prazo_anos
        self.data_referencia = data_referencia
        # Data inicial da janela de an√°lise
        self.data_inicio = data_inicio
        self.ativos_para_otimizar = []
        self.retornos_medios = None
        self.matriz_covariancia = None
        self.historico_retornos = None
        self.tickers = None

    def _preparar_dados(self):
        """Busca dados e aplica o ajuste de risco pelo prazo."""
        with self.app.app_context():
            query_ativos = db.session.query(Ativo).filter(
                ~Ativo.id.in_(self.ids_ativos_restringidos),
                Ativo.tipo == TipoAtivo.ACAO
            )
            self.ativos_para_otimizar = query_ativos.all()
            if len(self.ativos_para_otimizar) < 3:  # M√≠nimo para 3 objetivos
                raise ValueError("S√£o necess√°rios pelo menos 3 ativos do tipo 'A√ß√£o' para a otimiza√ß√£o.")

            ids_para_otimizar = [a.id for a in self.ativos_para_otimizar]
            query_historico = db.session.query(
                HistoricoPrecos.data,
                HistoricoPrecos.variacao_mensal,
                Ativo.ticker
            ).join(Ativo, HistoricoPrecos.id_ativo == Ativo.id) \
                .filter(HistoricoPrecos.id_ativo.in_(ids_para_otimizar))

            # ‚úÖ BACKTEST: Se data_referencia foi fornecida, filtra apenas dados at√© essa data
            if self.data_referencia is not None:
                if self.data_inicio is not None:
                    query_historico = query_historico.filter(HistoricoPrecos.data >= self.data_inicio)

                query_historico = query_historico.filter(HistoricoPrecos.data <= self.data_referencia)
                print(f"  üìÖ MODO BACKTEST: Usando dados at√© {self.data_referencia}")

            query_historico = query_historico.order_by(HistoricoPrecos.data)

            # ‚úÖ CORRE√á√ÉO: Usar connection em vez de bind
            df_historico = pd.read_sql(
                query_historico.statement,
                con=db.session.connection()
            )
            if df_historico.empty:
                raise ValueError("Sem hist√≥rico para os ativos selecionados.")

            # ‚úÖ FILTRO INTELIGENTE DE ATIVOS POR HIST√ìRICO M√çNIMO
            # Problema: a√ß√µes com hist√≥rico curto fazem .dropna() eliminar dados de a√ß√µes com hist√≥rico longo
            # Solu√ß√£o: Filtrar a√ß√µes antes do pivot baseado no horizonte de investimento

            # Calcula hist√≥rico m√≠nimo necess√°rio
            # Usa margem de 1.5x o prazo para ter mais dados de qualidade
            MARGEM_SEGURANCA = 1.5
            MINIMO_ABSOLUTO_MESES = 24  # M√≠nimo de 2 anos mesmo para prazos curtos

            historico_minimo_meses = max(
                int(self.prazo_anos * 12 * MARGEM_SEGURANCA),
                MINIMO_ABSOLUTO_MESES
            )

            print(f"\n{'=' * 70}")
            print(f"üîç FILTRANDO ATIVOS POR HIST√ìRICO M√çNIMO")
            print(f"{'=' * 70}")
            print(f"  Prazo de investimento: {self.prazo_anos} anos")
            print(f"  Hist√≥rico m√≠nimo requerido: {historico_minimo_meses} meses ({historico_minimo_meses/12:.1f} anos)")
            print(f"  Margem de seguran√ßa: {MARGEM_SEGURANCA}x")

            # Pivot sem dropna para analisar cada ativo
            df_retornos_completo = df_historico.pivot(
                index='data',
                columns='ticker',
                values='variacao_mensal'
            )

            # Analisa quantidade de dados por ativo
            ativos_disponiveis = df_retornos_completo.columns.tolist()
            contagem_dados = df_retornos_completo.count()

            print(f"\n  üìä An√°lise de hist√≥rico por ativo:")
            print(f"  {'Ticker':<12} {'Meses':>8} {'Status':<20}")
            print(f"  {'-'*40}")

            ativos_validos = []
            ativos_excluidos = []

            for ticker in ativos_disponiveis:
                meses_disponiveis = contagem_dados[ticker]

                if meses_disponiveis >= historico_minimo_meses:
                    status = "‚úÖ Inclu√≠do"
                    ativos_validos.append(ticker)
                else:
                    status = f"‚ùå Exclu√≠do ({meses_disponiveis}/{historico_minimo_meses})"
                    ativos_excluidos.append(ticker)

                print(f"  {ticker:<12} {meses_disponiveis:>8} {status:<20}")

            # Valida√ß√£o: precisamos de pelo menos 3 ativos
            if len(ativos_validos) < 3:
                raise ValueError(
                    f"Ativos insuficientes ap√≥s filtro de hist√≥rico!\n"
                    f"  Requerido: 3 ativos\n"
                    f"  Dispon√≠vel: {len(ativos_validos)} ativos\n"
                    f"  Hist√≥rico m√≠nimo: {historico_minimo_meses} meses\n\n"
                    f"Sugest√µes:\n"
                    f"  1. Reduza o prazo de investimento (atual: {self.prazo_anos} anos)\n"
                    f"  2. Adicione ativos com mais hist√≥rico ao universo\n"
                    f"  3. Use um per√≠odo de an√°lise mais recente (data_inicio)"
                )

            print(f"\n  ‚úÖ Resultado do filtro:")
            print(f"     Ativos inclu√≠dos: {len(ativos_validos)}")
            print(f"     Ativos exclu√≠dos: {len(ativos_excluidos)}")

            if ativos_excluidos:
                print(f"     Exclu√≠dos: {', '.join(ativos_excluidos)}")

            # Filtra o DataFrame original para incluir apenas ativos v√°lidos
            df_historico_filtrado = df_historico[df_historico['ticker'].isin(ativos_validos)]

            # Agora faz o pivot e dropna com seguran√ßa
            # Todos os ativos t√™m hist√≥rico >= m√≠nimo, ent√£o dropna √© consistente
            df_retornos = df_historico_filtrado.pivot(
                index='data',
                columns='ticker',
                values='variacao_mensal'
            ).dropna()

            self.tickers = df_retornos.columns.tolist()

            # Atualiza lista de ativos para otimizar (remove os exclu√≠dos)
            self.ativos_para_otimizar = [
                a for a in self.ativos_para_otimizar
                if a.ticker in self.tickers
            ]

            # ‚úÖ Valida√ß√£o de dados suficientes
            if len(df_retornos) < historico_minimo_meses:
                raise ValueError(
                    f"Dados hist√≥ricos insuficientes ap√≥s alinhamento!\n"
                    f"  Encontrados: {len(df_retornos)} meses\n"
                    f"  Necess√°rio: {historico_minimo_meses} meses\n\n"
                    f"Isso geralmente acontece quando o per√≠odo de sobreposi√ß√£o entre "
                    f"os ativos √© muito curto."
                )

            if self.data_referencia is not None:
                print(f"\n{'=' * 70}")
                print(f"üìÖ MODO BACKTEST ATIVADO")
                print(f"{'=' * 70}")
                print(f"  Data de refer√™ncia: {self.data_referencia}")
                print(f"  ‚ö†Ô∏è  Usando APENAS dados hist√≥ricos at√© essa data")

            print(f"\n  ‚úÖ Per√≠odo hist√≥rico: {len(df_retornos)} meses")
            print(f"  üìÖ De {df_retornos.index.min()} at√© {df_retornos.index.max()}")

            # Calcular estat√≠sticas
            self.retornos_medios = df_retornos.mean()
            self.matriz_covariancia = df_retornos.cov()
            matriz_corr = df_retornos.corr()

            # ‚úÖ PRINTAR MATRIZ DE CORRELA√á√ÉO
            print(f"\n{'=' * 70}")
            print(f"üìä MATRIZ DE CORRELA√á√ÉO")
            print(f"{'=' * 70}")
            _printar_matriz(matriz_corr, formato=".3f")

            # An√°lise da correla√ß√£o
            self._analisar_correlacao(matriz_corr)

            # ‚úÖ PRINTAR MATRIZ DE COVARI√ÇNCIA
            print(f"\n{'=' * 70}")
            print(f"üìä MATRIZ DE COVARI√ÇNCIA (Mensal)")
            print(f"{'=' * 70}")
            _printar_matriz(self.matriz_covariancia, formato=".6f")

            self.historico_retornos = df_retornos

            # Estat√≠sticas gerais
            print(f"\n{'=' * 70}")
            print(f"üìä ESTAT√çSTICAS GERAIS")
            print(f"{'=' * 70}")
            print(f"  Retorno m√©dio mensal: {self.retornos_medios.mean() * 100:.2f}%")
            print(f"  Volatilidade m√©dia: {np.sqrt(np.diag(self.matriz_covariancia)).mean() * 100:.2f}%")

            # Estat√≠sticas por ativo
            print(f"\n  üìà Por Ativo:")
            for ticker in df_retornos.columns:
                ret = self.retornos_medios[ticker] * 100
                vol = np.sqrt(self.matriz_covariancia.loc[ticker, ticker]) * 100
                sharpe = ret / vol if vol > 0 else 0
                print(f"     {ticker:8s} | Ret: {ret:6.2f}% | Vol: {vol:6.2f}% | Sharpe: {sharpe:5.2f}")

            print(f"\n  ‚úÖ Dados preparados com sucesso!")

    def _analisar_correlacao(self, matriz_corr):
        """
        Analisa e printa insights da matriz de correla√ß√£o
        """
        print(f"\n  üîç An√°lise de Correla√ß√£o:")

        # Extrair apenas metade superior (sem diagonal)
        mask = np.triu(np.ones_like(matriz_corr, dtype=bool), k=1)
        correlacoes = matriz_corr.where(mask).stack()

        # Estat√≠sticas
        print(f"     Correla√ß√£o M√©dia: {correlacoes.mean():.3f}")
        print(f"     Correla√ß√£o M√°xima: {correlacoes.max():.3f}")
        print(f"     Correla√ß√£o M√≠nima: {correlacoes.min():.3f}")

        # Pares com correla√ß√£o muito alta (> 0.8)
        altas = correlacoes[correlacoes > 0.8].sort_values(ascending=False)
        if len(altas) > 0:
            print(f"\n  ‚ö†Ô∏è  Pares com Correla√ß√£o ALTA (> 0.8):")
            for par, corr in altas.head(5).items():
                print(f"     {par[0]:8s} ‚Üî {par[1]:8s}: {corr:.3f}")

        # Pares com correla√ß√£o negativa (< -0.3)
        negativas = correlacoes[correlacoes < -0.3].sort_values()
        if len(negativas) > 0:
            print(f"\n  ‚úÖ Pares com Correla√ß√£o NEGATIVA (< -0.3) [Boa diversifica√ß√£o!]:")
            for par, corr in negativas.head(5).items():
                print(f"     {par[0]:8s} ‚Üî {par[1]:8s}: {corr:.3f}")

        # Aviso se tudo muito correlacionado
        if correlacoes.mean() > 0.7:
            print(f"\n  ‚ö†Ô∏è  ATEN√á√ÉO: Ativos muito correlacionados (m√©dia {correlacoes.mean():.2f})")
            print(f"     Considere adicionar ativos de outros setores para diversifica√ß√£o.")

    def _escolher_melhor_carteira(self, objetivos, solucoes):
        """Seleciona a melhor carteira da Fronteira de Pareto com base no perfil de risco."""
        print(f"Selecionando a melhor solu√ß√£o para o perfil '{self.nivel_risco}'...")

        # Normaliza os objetivos para que fiquem na mesma escala (0 a 1)
        # Obj 0 (Retorno) √© negativo, ent√£o invertemos o sinal para normalizar
        # Inverte retorno (era negativo)
        objetivos = objetivos.copy()
        objetivos[:, 0] = -objetivos[:, 0]

        # Normaliza√ß√£o mais robusta
        objetivos_norm = np.zeros_like(objetivos)
        for i in range(objetivos.shape[1]):
            col = objetivos[:, i]
            min_val, max_val = col.min(), col.max()

            if max_val - min_val > 1e-10:  # Evita divis√£o por zero
                objetivos_norm[:, i] = (col - min_val) / (max_val - min_val)
            else:
                objetivos_norm[:, i] = 0.5  # Valor neutro

        # Pesos para cada objetivo [Retorno, Vari√¢ncia, CVaR]
        pesos_perfil = {
            'conservador': np.array([0.2, 0.5, 0.3]),  # Prioriza minimizar riscos
            'moderado': np.array([0.4, 0.3, 0.3]),  # Equilibrado
            'arrojado': np.array([0.6, 0.2, 0.2])  # Prioriza maximizar retorno
        }
        pesos = pesos_perfil[self.nivel_risco]

        # Calcula um "score" para cada carteira.
        # Queremos maximizar o retorno (objetivo 0) e minimizar os outros (1 e 2).
        scores = ((objetivos_norm[:, 0] * pesos[0]) - (objetivos_norm[:, 1] * pesos[1]))
              #    - (objetivos_norm[:, 2] * pesos[2]))

        # O √≠ndice da carteira com o maior score √© a nossa escolha.
        idx_melhor = np.argmax(scores)
        return solucoes[idx_melhor]

    def otimizar(self, population_size: int = 100, generations: int = 50,
                 crossover_eta: float = 15.0, mutation_eta: float = 20.0,
                 convergence_tracker=None):
        """
        Orquestra o processo completo de otimiza√ß√£o personalizada.

        Args:
            population_size: Tamanho da popula√ß√£o para o NSGA-II
            generations: N√∫mero de gera√ß√µes
            crossover_eta: Par√¢metro eta do crossover
            mutation_eta: Par√¢metro eta da muta√ß√£o
            convergence_tracker: Inst√¢ncia de ConvergenceTracker para rastrear converg√™ncia (opcional)

        Returns:
            dict: Dicion√°rio contendo:
                - composicao: Lista de dicion√°rios com id_ativo, ticker e peso
                - data_referencia: Data de refer√™ncia usada (None se n√£o for backtest)
                - periodo_inicio: Data inicial dos dados hist√≥ricos usados
                - periodo_fim: Data final dos dados hist√≥ricos usados
                - num_meses: N√∫mero de meses de dados hist√≥ricos utilizados
        """
        self._preparar_dados()

        problema = PersonalizedPortfolioProblem(
            retornos_medios=self.retornos_medios.values,
            matriz_covariancia=self.matriz_covariancia.values,
            historico_retornos=self.historico_retornos.values,
            tickers = self.tickers,
            nivel_risco=self.nivel_risco
        )

        sampling = SimplexSampling()
        crossover = SimplexCrossover(eta=crossover_eta)
        mutation = SimplexMutation(eta=mutation_eta)

        algoritmo = NSGA2(pop_size=population_size, crossover=crossover,
                         mutation=mutation, sampling=sampling)

        # Prepara callback se tracker foi fornecido
        callback = None
        if convergence_tracker is not None:
            callback = ConvergenceCallback(convergence_tracker)

        resultado = minimize(problema, algoritmo, ('n_gen', generations),
                           callback=callback, verbose=True)
        print("üèÅ Otimiza√ß√£o NSGA-II conclu√≠da.")

        if resultado.X is None:
            raise ValueError("O algoritmo n√£o conseguiu encontrar nenhuma solu√ß√£o.")

        # Seleciona a melhor carteira da fronteira de Pareto
        pesos_otimos = self._escolher_melhor_carteira(resultado.F, resultado.X)

        F = resultado.F
        plt.scatter(F[:, 1], -F[:, 0], c=F[:, 2], cmap='viridis')
        plt.xlabel("Risco (vari√¢ncia)")
        plt.ylabel("Retorno esperado")
        plt.colorbar(label="CVaR")
        plt.title("Fronteira de Pareto - NSGA-II")
        plt.show()

        composicao_final = []
        for i, ativo in enumerate(self.ativos_para_otimizar):
            peso = pesos_otimos[i]
            if peso > 0.001:  # Ignora pesos insignificantes
                composicao_final.append({
                    'id_ativo': ativo.id,
                    'ticker': ativo.ticker,
                    'nome': ativo.nome,
                    'peso': float(peso)
                })

        # Normalizar pesos para soma = 1
        soma_pesos = sum(item['peso'] for item in composicao_final)
        for item in composicao_final:
            item['peso'] = item['peso'] / soma_pesos

        print(f"  ‚úÖ Carteira otimizada com {len(composicao_final)} ativos")

        # ‚úÖ RETORNA informa√ß√µes adicionais sobre o per√≠odo usado (√∫til para backtest)
        resultado = {
            'composicao': composicao_final,
            'data_referencia': self.data_referencia,
            'periodo_inicio': self.historico_retornos.index.min(),
            'periodo_fim': self.historico_retornos.index.max(),
            'num_meses': len(self.historico_retornos),
            'modo_backtest': self.data_referencia is not None
        }

        return resultado


def _calcular_retorno_carteira(app, carteira: List[Dict],
                               data_inicio,
                               data_fim) -> Tuple[float, List[float]]:
    """
    Calcula o retorno de uma carteira em um per√≠odo espec√≠fico

    Args:
        carteira: Lista com composi√ß√£o da carteira
        data_inicio: Data inicial do per√≠odo
        data_fim: Data final do per√≠odo

    Returns:
        Tupla com (retorno_total, lista_de_retornos_mensais)
    """
    with app.app_context():
        # Buscar retornos dos ativos no per√≠odo
        ids_ativos = [item['id_ativo'] for item in carteira]

        query = db.session.query(
            HistoricoPrecos.data,
            HistoricoPrecos.variacao_mensal,
            Ativo.ticker
        ).join(Ativo, HistoricoPrecos.id_ativo == Ativo.id) \
            .filter(
            HistoricoPrecos.id_ativo.in_(ids_ativos),
            HistoricoPrecos.data > data_inicio,
            HistoricoPrecos.data <= data_fim
        ) \
            .order_by(HistoricoPrecos.data)

        df = pd.read_sql(query.statement, con=db.session.connection())

        if df.empty:
            return 0.0, []

        # Pivot para ter retornos por ativo
        df_retornos = df.pivot(
            index='data',
            columns='ticker',
            values='variacao_mensal'
        )

        # Calcular retorno ponderado da carteira
        pesos_dict = {item['ticker']: item['peso'] for item in carteira}

        retornos_mensais = []
        for data_idx in df_retornos.index:
            retorno_mes = 0
            for ticker in df_retornos.columns:
                if ticker in pesos_dict:
                    ret_ativo = df_retornos.loc[data_idx, ticker]
                    if pd.notna(ret_ativo):
                        retorno_mes += pesos_dict[ticker] * ret_ativo

            retornos_mensais.append(retorno_mes)

        # Calcular retorno acumulado
        retorno_total = (1 + pd.Series(retornos_mensais)).prod() - 1

        return float(retorno_total), retornos_mensais


def otimizar_carteira_atual(app):
    print("\n" + "=" * 80)
    print("EXEMPLO 1: Otimiza√ß√£o normal (usando todos os dados dispon√≠veis)")
    print("=" * 80)
    service = Nsga2OtimizacaoService(app, [1], "conservador", 2)
    resultado = service.otimizar()
    print(f"\n‚úÖ Resultado:")
    print(f"   Composi√ß√£o: {resultado['composicao']}")
    print(f"   Per√≠odo: {resultado['periodo_inicio']} at√© {resultado['periodo_fim']}")
    print(f"   Meses: {resultado['num_meses']}")

def backtest(app):
    from datetime import date
    print("\n" + "=" * 80)
    print("EXEMPLO 2: Otimiza√ß√£o com BACKTEST (dados at√© 2023-12-31)")
    print("=" * 80)
    data_backtest = date(2023, 1, 1)
    service_backtest = Nsga2OtimizacaoService(app, [1], "moderado", 2, data_referencia=data_backtest)
    carteira_backtest = service_backtest.otimizar()
    print(f"\n‚úÖ Resultado do Backtest:")
    print(f"   Composi√ß√£o: {carteira_backtest['composicao']}")
    print(f"   Data de refer√™ncia: {carteira_backtest['data_referencia']}")
    print(f"   Per√≠odo: {carteira_backtest['periodo_inicio']} at√© {carteira_backtest['periodo_fim']}")
    print(f"   Meses: {carteira_backtest['num_meses']}")
    print(f"   Modo Backtest: {carteira_backtest['modo_backtest']}")

    dataFim = date(2025, 10, 20)
    retorno_periodo, retornos_mensais = _calcular_retorno_carteira(
        app,
        carteira_backtest['composicao'],
        data_backtest,
        dataFim
    )

    print(f"     Retorno Acumulado: {retorno_periodo * 100:+.2f}%")


def main():
    """Fun√ß√£o principal que interpreta os comandos."""
    app = create_app()

    # Exemplo 1: Otimiza√ß√£o normal (sem backtest)
   # otimizar_carteira_atual(app)

    # Exemplo 2: Otimiza√ß√£o com backtest (usando dados at√© uma data espec√≠fica)
    backtest(app)


if __name__ == "__main__":
    main()

